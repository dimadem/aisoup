{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RAG:\n",
    "\n",
    "In this tutorial, we will focus on the following topics:\n",
    "- What is a vector database and how to work with it.\n",
    "- What is a chunk and how to split text into chunks.\n",
    "- What is embedding and how to embed chunks and upsert them into a vector database.\n",
    "- How to query our vector database collection and retrieve data from it using LLM.\n",
    "\n",
    "---\n",
    "tools:\n",
    "* [anthropic](https://github.com/anthropics/anthropic-sdk-python)\n",
    "* [chromadb](https://github.com/chroma-core/chroma)\n",
    "* [sentence_transformers](https://sbert.net/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Lets import our api_key to project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load .env\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "# get API key\n",
    "api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "print(\"api_key -> \", api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "\n",
    "client = Anthropic(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Create collection:**\n",
    "Chroma lets you manage collections of embeddings, using the collection primitive.\n",
    "\n",
    "Chroma collections are created with a name and an optional embedding function. If you supply an embedding function, you must supply it every time you get the collection.\n",
    "\n",
    "---\n",
    "#### **Embedding function:**\n",
    "\n",
    "- all-MiniLM-L6-v2\n",
    "- context length < 256 tokens\n",
    "- embedding dimension 384\n",
    "\n",
    "Embeddings are the A.I-native way to represent any kind of data, making them the perfect fit for working with all kinds of A.I-powered tools and algorithms. They can represent text, images, and soon audio and video. There are many options for creating embeddings, whether locally using an installed library, or by calling an API.\n",
    "\n",
    "Chroma provides lightweight wrappers around popular embedding providers, making it easy to use them in your apps. You can set an embedding function when you create a Chroma collection, which will be used automatically, or you can call them directly yourself.\n",
    "\n",
    "---\n",
    "### 🍜 New ingredients!\n",
    "\n",
    "- import chromadb - vector database read [documentation](https://docs.trychroma.com/reference/py-client)\n",
    "\n",
    "\n",
    "- from chromadb.utils import embedding_functions - [read more](https://docs.trychroma.com/guides/embeddings#default:-all-minilm-l6-v2)\n",
    "\n",
    "- [Voyage embedding](https://docs.anthropic.com/en/docs/build-with-claude/embeddings)\n",
    "\n",
    "- [sentence_transformers](https://sbert.net/)\n",
    "\n",
    "\n",
    "- [Gemini text Embedding](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings#generative-ai-get-text-embedding-python_vertex_ai_sdk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import pprint\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# declare default embedding function [all-MiniLM-L6-v2]\n",
    "default_embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "collection_name = \"my_first_collection\"\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chromadb/\")\n",
    "# declare ChromaDB collection\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=collection_name,\n",
    "    embedding_function=default_embedding_function\n",
    "    )\n",
    "\n",
    "result = collection.get()\n",
    "\n",
    "print(f\"Collection {collection_name} created successfully\")\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Load txt from dir:\n",
    "- For now we process just text files.\n",
    "\n",
    "But in real world, we might parse and process documents. \n",
    "\n",
    "In other words - prepare them for working with our pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "def load_txt_from_dir(dir_path):\n",
    "    documents = []\n",
    "    for filename in os.listdir(dir_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(dir_path, filename), \"r\") as file:\n",
    "                documents.append({\"text\": file.read()})\n",
    "    return documents\n",
    "\n",
    "#--------------------------------------------#\n",
    "\n",
    "directory_path = \"../files/txt\"\n",
    "\n",
    "# load documents from directory\n",
    "txt_files = load_txt_from_dir(directory_path)\n",
    "\n",
    "print(f\" {len(txt_files)} files loaded\")\n",
    "pprint.pprint(txt_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Split text into chunks:\n",
    "\n",
    "[Advanced Chunking Techniques for LLM](https://www.rungalileo.io/blog/mastering-rag-advanced-chunking-techniques-for-llm-applications)\n",
    "\n",
    "\n",
    "[Unstructured](https://unstructured.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "def split_text(\n",
    "    text, \n",
    "    chunk_size=256, \n",
    "    chunk_overlap=20\n",
    "    ):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    text_length = len(text)\n",
    "    while start < text_length:\n",
    "        end = start + chunk_size\n",
    "        chunks.append(text[start:end])\n",
    "        start = end - chunk_overlap\n",
    "    return chunks\n",
    "\n",
    "# split text into chunks\n",
    "chunked_txt = []\n",
    "\n",
    "for file_id, txt_file in enumerate(txt_files):\n",
    "    chunks = split_text(txt_file[\"text\"])\n",
    "    for chunk_id, chunk in enumerate(chunks):\n",
    "        chunked_txt.append(\n",
    "            {\n",
    "                'id': f\"{file_id}-{chunk_id}\", \n",
    "                'text': chunk,\n",
    "            }\n",
    "        )\n",
    "\n",
    "print(f\"Split in to {len(chunked_txt)} chunks\\n\\n\")\n",
    "\n",
    "pprint.pprint(chunked_txt[13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Upsert data to ChromaDB:\n",
    "\n",
    "If Chroma is passed a list of documents, it will automatically tokenize and embed them with the collection's embedding function (the default will be used if none was supplied at collection creation). Chroma will also store the documents themselves. If the documents are too large to embed using the chosen embedding function, an exception will be raised.\n",
    "\n",
    "Each document must have a unique associated id. Trying to .add the same ID twice will result in only the initial value being stored. An optional list of metadata dictionaries can be supplied for each document, to store additional information and enable filtering.\n",
    "\n",
    "Alternatively, you can supply a list of document-associated embeddings directly, and Chroma will store the associated documents without embedding them itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsert documents with embeddings to collection ChromaDB\n",
    "for chunk in chunked_txt :\n",
    "    collection.upsert(\n",
    "            ids=chunk['id'],\n",
    "            documents=chunk['text'],\n",
    "    )\n",
    "\n",
    "\n",
    "print(f\"Collection {collection_name} has {collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Query collection:\n",
    "\n",
    "You can also query by a set of **query_texts**.\n",
    " \n",
    "Chroma will first embed each **query_text** with the collection's embedding function, and then perform the query with the generated embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "# function to query collection\n",
    "def query_collection(question, n_results=5):\n",
    "    results = collection.query(\n",
    "        query_texts=question,\n",
    "        n_results=n_results,\n",
    "        # include=['embeddings', 'documents', 'distances']\n",
    "    )\n",
    "    # pprint.pprint(results)\n",
    "    \n",
    "    # extract relevant chunks\n",
    "    relevant_chunks = [txt for sublist in results[\"documents\"] for txt in sublist]\n",
    "    # pprint.pprint(relevant_chunks)\n",
    "    # for idx, txt in enumerate(results[\"documents\"]):\n",
    "    #     txt_id = results[\"ids\"][0][idx]\n",
    "    #     distance = results[\"distances\"][0][idx]\n",
    "    #     print(\"Chunks found:\")\n",
    "    #     print(f\"document id: {txt_id}\")\n",
    "    #     print(f\"text found:  {txt}\")\n",
    "    #     print(f\"distance:    {distance}\\n\\n\")\n",
    "\n",
    "    return relevant_chunks\n",
    "\n",
    "\n",
    "# function for generate response with openai\n",
    "def api_response(query, relevant_chunks):\n",
    "    \n",
    "    context = \"\\n\\n\".join(relevant_chunks)\n",
    "    \n",
    "    user_prompt = (f\"\"\"\n",
    "            You have been tasked with helping us to answer the following query: \n",
    "            <query>\n",
    "            {query}\n",
    "            </query>\n",
    "            You have access to the following documents which are meant to provide context as you answer the query:\n",
    "            <documents>\n",
    "            {context}\n",
    "            </documents>\n",
    "            Please remain faithful to the underlying context, and only deviate from it if you are 100% sure that you know the answer already. \n",
    "            Answer the question now, and avoid providing preamble such as 'Here is the answer', etc\n",
    "            \"\"\"\n",
    "            )\n",
    "    \n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=2048,\n",
    "        messages=[{\n",
    "                \"role\": \"user\", \n",
    "                \"content\": user_prompt\n",
    "                }],\n",
    "        temperature=0\n",
    "\n",
    "    )\n",
    "    return response.content[0].text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Finally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query collection\n",
    "\n",
    "question = \"What lego product we have?\"\n",
    "relevant_chunks = query_collection(question)\n",
    "answer = api_response(question, relevant_chunks)\n",
    "print(\"\\n------------------------------------\\n\")\n",
    "print(\"answer\\n\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## well done!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's cleanup db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### list collections \n",
    "here we check do we have any list_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_collections = chroma_client.list_collections()\n",
    "\n",
    "print(list_collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### delete collection\n",
    "here we delete specific collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client.delete_collection(collection_name)\n",
    "\n",
    "list_collections = chroma_client.list_collections()\n",
    "\n",
    "print(list_collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "made with <3 by \n",
    "[dima dem](https://github.com/dimadem/) |42London"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
